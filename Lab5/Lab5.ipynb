{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read annotated corpora with NLTK\n",
    "# first download data\n",
    "import nltk\n",
    "from includes import *\n",
    "\n",
    "#nltk.download()\n",
    "# it will open a GUI and you have to double click in \"all\" to download \n",
    "# this will download different types of annotated corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the complete **PTB** data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect PoS from Treebank\n",
    "# we use the universal tagset\n",
    "treebank_sents = nltk.corpus.treebank.tagged_sents(tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the ids of sentences corresponding to training, development, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 114 800\n"
     ]
    }
   ],
   "source": [
    "training_ids = [int(i) for i in open('training.ids') if i.strip()]\n",
    "development_ids = [int(i) for i in open('development.ids') if i.strip()]\n",
    "test_ids = [int(i) for i in open('test.ids') if i.strip()]\n",
    "print(len(training_ids), len(development_ids), len(test_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we separate the 3 parts of the annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb_train = [treebank_sents[i] for i in training_ids]\n",
    "ptb_dev = [treebank_sents[i] for i in development_ids]\n",
    "ptb_test = [treebank_sents[i] for i in test_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We *suggest* you print details about the data such as number of unique words/tags, total tokens, number of sentences, etc.\n",
    "2. Then you can copy here your implementation from lab4 or import it from a separate python file if you want (but make sure to submit those too)\n",
    "3. Then you can go on with training/development and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are just **tips** (you need not necessarily follow them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences(treebank_corpus):\n",
    "    sentences = []\n",
    "    for observations in treebank_corpus:\n",
    "        sentences.append([x for x, c in observations])\n",
    "    return sentences\n",
    "\n",
    "def accuracy(gold_sequences, pred_sequences):\n",
    "    \"\"\"\n",
    "    Return percentage of instances in the test data that our tagger labeled correctly.\n",
    "    \n",
    "    :param gold_sequences: a list of tag sequences that can be assumed to be correct\n",
    "    :param pred_sequences: a list of tag sequences predicted by Viterbi    \n",
    "    \"\"\"\n",
    "    count_correct, count_total = 0, 0\n",
    "    for i, combined in enumerate(zip(pred_sequences, gold_sequences)):\n",
    "        for p, g in list(zip(*combined)):\n",
    "            if p == g:\n",
    "                count_correct += 1\n",
    "            count_total += 1\n",
    "    if count_total:\n",
    "        return count_correct / count_total\n",
    "    return None\n",
    "\n",
    "def predict_corpus(test_set, hmm):\n",
    "    \"\"\"\n",
    "    Returns viterbi predictions for all sentences in a given corpus\n",
    "    \n",
    "    :param test_set: A corpus of tagged sentences\n",
    "    :param hmm     : A language model\n",
    "    \"\"\"\n",
    "    gold_sequences, pred_sequences = list(), list()\n",
    "    print('Making predictions', end='')\n",
    "    for i, sequence in enumerate(test_set):\n",
    "        if i % round(len(test_set) / 10) == 0:\n",
    "            print('.', end='')\n",
    "        sentence , tags = map(list, zip(*sequence))\n",
    "        viterbi_tags, _ = viterbi_recursion(sentence, hmm)\n",
    "        gold_sequences.append(tags)\n",
    "        pred_sequences.append(viterbi_tags)\n",
    "    print()\n",
    "    return gold_sequences, pred_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a, b: 0.01 0.01\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 0.01 0.1\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 0.01 1.0\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 0.01 10.0\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 0.1 0.01\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 0.1 0.1\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 0.1 1.0\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 0.1 10.0\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 1.0 0.01\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 1.0 0.1\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 1.0 1.0\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 1.0 10.0\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 10.0 0.01\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 10.0 0.1\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 10.0 1.0\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "a, b: 10.0 10.0\n",
      "Start counting\n",
      "Start calculating cpd's\n",
      "..............\n",
      "Finished cpd's\n",
      "[<includes.HMMLM object at 0x7fae99cb3240>, <includes.HMMLM object at 0x7fae99bb43c8>, <includes.HMMLM object at 0x7fae99acb198>, <includes.HMMLM object at 0x7fae999a29e8>, <includes.HMMLM object at 0x7fae99901780>, <includes.HMMLM object at 0x7fae997e0438>, <includes.HMMLM object at 0x7fae9973c860>, <includes.HMMLM object at 0x7fae9973ccf8>, <includes.HMMLM object at 0x7fae99698390>, <includes.HMMLM object at 0x7fae994cd908>, <includes.HMMLM object at 0x7fae993abe48>, <includes.HMMLM object at 0x7fae99307e10>, <includes.HMMLM object at 0x7fae991e2f60>, <includes.HMMLM object at 0x7fae9913e6a0>, <includes.HMMLM object at 0x7fae9909abe0>, <includes.HMMLM object at 0x7fae98f76f60>]\n"
     ]
    }
   ],
   "source": [
    "# Grid search for hyperparameters\n",
    "models = []\n",
    "for alpha in [0.01, 0.1, 1., 10.]:\n",
    "    for beta in [0.01, 0.1, 1., 10.]:\n",
    "        print(\"a, b:\", alpha, beta)\n",
    "        hmm = HMMLM(alpha, beta)\n",
    "        hmm.estimate_model(ptb_train)\n",
    "        models.append(hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...........\n",
      "Making predictions...........\n",
      "Making predictions...........\n",
      "Making predictions...........\n",
      "Making predictions...........\n",
      "Making predictions...........\n",
      "Making predictions...........\n",
      "Making predictions...........\n",
      "Making predictions...........\n",
      "Making predictions...........\n",
      "Making predictions...........\n",
      "Making predictions...........\n",
      "Making predictions...........\n",
      "Making predictions...........\n",
      "Making predictions...........\n",
      "Making predictions...........\n",
      "\n",
      "  alpha    beta      ppl       acc\n",
      "-------  ------  -------  --------\n",
      "   0.01    0.01  4.56627  0.880875\n",
      "   0.01    0.1   4.41098  0.880875\n",
      "   0.01    1     4.68071  0.841057\n",
      "   0.01   10     5.53552  0.751632\n",
      "   0.1     0.01  4.56626  0.880875\n",
      "   0.1     0.1   4.41095  0.880875\n",
      "   0.1     1     4.68069  0.841057\n",
      "   0.1    10     5.53551  0.751632\n",
      "   1       0.01  4.56613  0.880548\n",
      "   1       0.1   4.41072  0.880875\n",
      "   1       1     4.68042  0.841057\n",
      "   1      10     5.53537  0.751632\n",
      "  10       0.01  4.56519  0.878264\n",
      "  10       0.1   4.40871  0.881201\n",
      "  10       1     4.67807  0.842363\n",
      "  10      10     5.53424  0.753264\n"
     ]
    }
   ],
   "source": [
    "sents = extract_sentences(ptb_dev)\n",
    "results = []\n",
    "for model in models:\n",
    "    a = model._transition_alpha\n",
    "    b = model._emission_alpha\n",
    "    ppl = log_perplexity(sents, model)\n",
    "    acc = accuracy(*predict_corpus(ptb_dev, model))\n",
    "    results.append([a, b, ppl, acc])\n",
    "\n",
    "\n",
    "headers = ['alpha', 'beta', 'ppl', 'acc']\n",
    "\n",
    "print()\n",
    "print(tabulate(results, headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.0, 0.1, 4.408709283788377, 0.881201044386423]\n",
      "Making predictions..........4.41 0.886\n"
     ]
    }
   ],
   "source": [
    "# Best test set model 13 with alpha 10 and beta 0.1\n",
    "# Both perplexity and accuracy are best at this model\n",
    "print(results[13])\n",
    "# Now use test set to calc perplexity and accuracy\n",
    "\n",
    "ppl = log_perplexity(extract_sentences(ptb_test), models[13])\n",
    "acc = accuracy(*predict_corpus(ptb_test, models[13]))\n",
    "print(round(ppl,3), round(acc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use *tabulate* to print some examples. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate_example(sentence, gold_pos, pred_pos):\n",
    "    illustration = []\n",
    "    for w, g, p in zip(sentence, gold_pos, pred_pos):\n",
    "        illustration.append([w, g, p])\n",
    "    return illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word             Gold    Pred\n",
      "---------------  ------  ------\n",
      "But              CONJ    ADJ\n",
      "Rep.             NOUN    NOUN\n",
      "Marge            NOUN    ADP\n",
      "Roukema          NOUN    NOUN\n",
      "-LRB-            .       .\n",
      "R.               NOUN    NOUN\n",
      ",                .       .\n",
      "N.J              NOUN    NOUN\n",
      ".                .       .\n",
      "-RRB-            .       .\n",
      "instead          ADV     ADV\n",
      "praised          VERB    ADP\n",
      "the              DET     DET\n",
      "House            NOUN    NOUN\n",
      "'s               PRT     PRT\n",
      "acceptance       NOUN    NOUN\n",
      "of               ADP     ADP\n",
      "a                DET     DET\n",
      "new              ADJ     ADJ\n",
      "youth            NOUN    NOUN\n",
      "``               .       .\n",
      "training         NOUN    NOUN\n",
      "''               .       .\n",
      "wage             NOUN    NOUN\n",
      ",                .       .\n",
      "a                DET     DET\n",
      "subminimum       NOUN    NOUN\n",
      "that             ADP     ADP\n",
      "GOP              NOUN    NOUN\n",
      "administrations  NOUN    PRT\n",
      "have             VERB    VERB\n",
      "sought           VERB    VERB\n",
      "*T*-1            X       X\n",
      "for              ADP     ADP\n",
      "many             ADJ     ADJ\n",
      "years            NOUN    NOUN\n",
      ".                .       .\n",
      "accuracy: 0.8919\n",
      "\n",
      "Word        Gold    Pred\n",
      "----------  ------  ------\n",
      "Reserves    NOUN    PRON\n",
      "traded      VERB    VERB\n",
      "*           X       X\n",
      "among       ADP     ADP\n",
      "commercial  ADJ     ADJ\n",
      "banks       NOUN    NOUN\n",
      "for         ADP     ADP\n",
      "overnight   ADJ     DET\n",
      "use         NOUN    NOUN\n",
      "in          ADP     ADP\n",
      "amounts     NOUN    NOUN\n",
      "of          ADP     ADP\n",
      "$           .       .\n",
      "1           NUM     NUM\n",
      "million     NUM     NUM\n",
      "or          CONJ    CONJ\n",
      "more        ADJ     ADJ\n",
      "*U*         X       X\n",
      ".           .       .\n",
      "accuracy: 0.8947\n",
      "\n",
      "Word       Gold    Pred\n",
      "---------  ------  ------\n",
      "But        CONJ    PRON\n",
      "advancing  VERB    VERB\n",
      "issues     NOUN    NOUN\n",
      "on         ADP     ADP\n",
      "the        DET     DET\n",
      "New        NOUN    ADJ\n",
      "York       NOUN    NOUN\n",
      "Stock      NOUN    NOUN\n",
      "Exchange   NOUN    NOUN\n",
      "were       VERB    VERB\n",
      "tidily     ADV     ADV\n",
      "ahead      ADV     ADV\n",
      "of         ADP     ADP\n",
      "declining  VERB    DET\n",
      "stocks     NOUN    NOUN\n",
      ",          .       .\n",
      "847        NUM     NUM\n",
      "to         PRT     PRT\n",
      "644        NUM     NUM\n",
      ".          .       .\n",
      "accuracy: 0.85\n",
      "\n",
      "Word        Gold    Pred\n",
      "----------  ------  ------\n",
      "They        PRON    PRON\n",
      "are         VERB    VERB\n",
      "n't         ADV     ADV\n",
      "accepted    VERB    VERB\n",
      "*-1         X       X\n",
      "everywhere  ADV     ADV\n",
      ",           .       .\n",
      "however     ADV     ADV\n",
      ".           .       .\n",
      "accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    sentence, gold = map(list, zip(*ptb_test[i]))\n",
    "    pred, _ = viterbi_recursion(sentence, models[13])\n",
    "    illustration = tabulate_example(sentence, gold, pred)\n",
    "    print()\n",
    "    print(tabulate(illustration, headers=['Word', 'Gold', 'Pred']))\n",
    "    print(\"accuracy:\",round(accuracy([gold], [pred]),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
